{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ping response: {'message': 'pong'}\n",
      "Inference response: {'message': 'Inference process started successfully', 'task_id': '888a1976-2a33-40c2-88fc-ecef27477b83', 'args': {'actual_steps': 19, 'ckpt': 'best_ema_inference_epoch_model.pt', 'confidence_ckpt': 'best_model_epoch75.pt', 'confidence_model_dir': './workdir/v1.1/confidence_model', 'different_schedules': False, 'inf_sched_alpha': 1, 'inf_sched_beta': 1, 'inference_steps': 20, 'initial_noise_std_proportion': 1.4601642460337794, 'limit_failures': 5, 'model_dir': './workdir/v1.1/score_model', 'no_final_step_noise': True, 'no_model': False, 'no_random': False, 'no_random_pocket': False, 'ode': False, 'old_confidence_model': True, 'old_score_model': False, 'resample_rdkit': False, 'samples_per_complex': 10, 'sigma_schedule': 'expbeta', 'temp_psi_rot': 0.9022615585677628, 'temp_psi_tor': 0.5946212391366862, 'temp_psi_tr': 0.727287304570729, 'temp_sampling_rot': 2.06391612594481, 'temp_sampling_tor': 7.044261621607846, 'temp_sampling_tr': 1.170050527854316, 'temp_sigma_data_rot': 0.7464326999906034, 'temp_sigma_data_tor': 0.6943254174849822, 'temp_sigma_data_tr': 0.9299802531572672, 'loglevel': 'WARNING', 'choose_residue': False, 'out_dir': 'results/user_inference', 'save_visualisation': False, 'batch_size': 10}}\n",
      "Inference status response: {'task_id': '888a1976-2a33-40c2-88fc-ecef27477b83', 'status': 'failed', 'error': \"name 'Namespace' is not defined\"}\n",
      "Task failed: name 'Namespace' is not defined\n",
      "Inference zip response: {'message': 'Inference process started successfully for zip file', 'task_id': '52e9a524-a040-44a0-a5e5-aab96da48ceb'}\n",
      "Inference status response: {'task_id': '52e9a524-a040-44a0-a5e5-aab96da48ceb', 'status': 'failed', 'error': 'Either PDB or SDF file is missing in the zip archive.'}\n",
      "Task failed: Either PDB or SDF file is missing in the zip archive.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "import json\n",
    "\n",
    "# URLs for local and remote testing\n",
    "LOCAL_URL = \"http://127.0.0.1:8001\"\n",
    "BASE_URL = \"http://51.159.160.67:8000\"\n",
    "\n",
    "# Choose the URL to use for testing\n",
    "USE_LOCAL = True\n",
    "URL = LOCAL_URL if USE_LOCAL else BASE_URL\n",
    "\n",
    "# Paths to test files\n",
    "test_sdf = \"/root/projects/DiffDock/examples/1a46_ligand.sdf\"\n",
    "test_pdb = \"/root/projects/DiffDock/examples/1a46_protein_processed.pdb\"\n",
    "test_zip = \"/root/projects/DiffDock/data/1a0q_test_data.zip\"\n",
    "\n",
    "# Test the /ping endpoint\n",
    "def test_ping():\n",
    "    response = requests.get(f\"{URL}/ping\")\n",
    "    print(\"Ping response:\", response.json())\n",
    "\n",
    "# Test the /inference endpoint with a sample PDB and SDF file\n",
    "def test_inference():\n",
    "    with open(test_pdb, \"rb\") as pdb_file, open(test_sdf, \"rb\") as sdf_file:\n",
    "        files = {\n",
    "            \"pdb_file\": pdb_file,\n",
    "            \"sdf_file\": sdf_file\n",
    "        }\n",
    "        body = {\n",
    "            \"input\": {\n",
    "                \"protein_path\": \"1a46_protein.pdb\",\n",
    "                \"ligand_description\": \"1a46_ligand.sdf\"\n",
    "            },\n",
    "            \"config\": {\n",
    "                \"inference_steps\": 20,\n",
    "                \"samples_per_complex\": 10\n",
    "            }\n",
    "        }\n",
    "        response = requests.post(f\"{URL}/inference\", files=files, data={\"body\": json.dumps(body)})\n",
    "        print(\"Inference response:\", response.json())\n",
    "        return response.json().get(\"task_id\")\n",
    "\n",
    "# Test the /inference/status endpoint\n",
    "def test_inference_status(task_id):\n",
    "    response = requests.get(f\"{URL}/inference/status/{task_id}\")\n",
    "    print(\"Inference status response:\", response.json())\n",
    "    return response.json()\n",
    "\n",
    "# Test the /inference/download endpoint\n",
    "def test_inference_download(task_id):\n",
    "    response = requests.get(f\"{URL}/inference/download/{task_id}\")\n",
    "    with open(f\"{task_id}_output.zip\", \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    print(f\"Downloaded result for task {task_id} to {task_id}_output.zip\")\n",
    "\n",
    "# Test the /inference/zip/ endpoint with a sample zip file\n",
    "def test_inference_zip():\n",
    "    with open(test_zip, \"rb\") as zip_file:\n",
    "        files = {\"zip_file\": zip_file}\n",
    "        config = {\n",
    "            \"inference_steps\": 20,\n",
    "            \"samples_per_complex\": 10\n",
    "        }\n",
    "        response = requests.post(f\"{URL}/inference/zip/\", files=files, data={\"config\": json.dumps(config)})\n",
    "        print(\"Inference zip response:\", response.json())\n",
    "        return response.json().get(\"task_id\")\n",
    "\n",
    "# Run tests\n",
    "test_ping()\n",
    "task_id = test_inference()\n",
    "\n",
    "while True:\n",
    "    status = test_inference_status(task_id)\n",
    "    if status.get('status') == 'completed':\n",
    "        test_inference_download(task_id)\n",
    "        break\n",
    "    elif status.get('status') == 'failed':\n",
    "        print(f\"Task failed: {status.get('error')}\")\n",
    "        break\n",
    "    time.sleep(10)\n",
    "\n",
    "task_id_zip = test_inference_zip()\n",
    "\n",
    "while True:\n",
    "    status = test_inference_status(task_id_zip)\n",
    "    if status.get('status') == 'completed':\n",
    "        test_inference_download(task_id_zip)\n",
    "        break\n",
    "    elif status.get('status') == 'failed':\n",
    "        print(f\"Task failed: {status.get('error')}\")\n",
    "        break\n",
    "    time.sleep(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /root/miniconda3/envs/diffdock/lib/python3.9/site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/miniconda3/envs/diffdock/lib/python3.9/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniconda3/envs/diffdock/lib/python3.9/site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/miniconda3/envs/diffdock/lib/python3.9/site-packages (from requests) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/envs/diffdock/lib/python3.9/site-packages (from requests) (2024.2.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRoot endpoint failed with status code: 404\n",
      "{'detail': 'Not Found'}\n",
      "Endpoint '/inference' failed with status code: 422\n",
      "{'detail': [{'type': 'missing', 'loc': ['body', 'input'], 'msg': 'Field required', 'input': {'key': 'value'}}, {'type': 'missing', 'loc': ['body', 'config'], 'msg': 'Field required', 'input': {'key': 'value'}}]}\n"
     ]
    }
   ],
   "source": [
    "# Jupyter Notebook Cell\n",
    "!pip install requests\n",
    "\n",
    "import requests\n",
    "\n",
    "# Define the base URL of your API\n",
    "base_url = 'http://51.159.189.40:8000'\n",
    "\n",
    "# Function to test the root endpoint\n",
    "def test_root_endpoint():\n",
    "    url = base_url\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        print(\"Root endpoint is working.\")\n",
    "    else:\n",
    "        print(f\"Root endpoint failed with status code: {response.status_code}\")\n",
    "    print(response.json())\n",
    "\n",
    "# Function to test a specific endpoint\n",
    "def test_specific_endpoint(endpoint, payload=None):\n",
    "    url = f\"{base_url}{endpoint}\"\n",
    "    if payload:\n",
    "        response = requests.post(url, json=payload)\n",
    "    else:\n",
    "        response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        print(f\"Endpoint '{endpoint}' is working.\")\n",
    "    else:\n",
    "        print(f\"Endpoint '{endpoint}' failed with status code: {response.status_code}\")\n",
    "    print(response.json())\n",
    "\n",
    "# Test the root endpoint\n",
    "test_root_endpoint()\n",
    "\n",
    "# Example of testing a specific endpoint\n",
    "# Replace 'your-endpoint' with the actual endpoint and adjust the payload if necessary\n",
    "test_specific_endpoint('/inference', payload={'key': 'value'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test script for direct input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14389/3150982447.py:56: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  response = requests.post(api_url, json={\"input\": inference_input.dict(), \"config\": inference_config.dict()})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference initiated successfully\n",
      "Task ID: d400ec06-e79e-45cd-a556-080693d5b039\n",
      "Progress: No such task\n",
      "Progress: No such task\n",
      "Progress: No such task\n",
      "Progress: No such task\n",
      "Progress: No such task\n",
      "Progress: No such task\n",
      "Progress: No such task\n",
      "Progress: No such task\n",
      "Progress: No such task\n",
      "Progress: No such task\n",
      "Progress: No such task\n",
      "Progress: No such task\n",
      "Progress: No such task\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 81\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResponse:\u001b[39m\u001b[38;5;124m\"\u001b[39m, response\u001b[38;5;241m.\u001b[39mtext)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 81\u001b[0m     \u001b[43mtest_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minference_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minference_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[20], line 73\u001b[0m, in \u001b[0;36mtest_inference\u001b[0;34m(api_url, progress_url, inference_input, inference_config)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to get progress\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 73\u001b[0m         \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to start inference\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# test_script.py\n",
    "\n",
    "import requests\n",
    "from schemas import InferenceInput, InferenceConfig\n",
    "import time\n",
    "\n",
    "# Define the URL of the FastAPI server\n",
    "api_url = \"http://127.0.0.1:8000/inference/\"\n",
    "progress_url = \"http://127.0.0.1:8000/inference/progress/\"\n",
    "\n",
    "# Example input data\n",
    "inference_input = InferenceInput(\n",
    "    protein_path=\"examples/6ahs_protein_processed.pdb\",\n",
    "    ligand_description=\"examples/6ahs_ligand.sdf\"\n",
    ")\n",
    "\n",
    "inference_config = InferenceConfig(\n",
    "    actual_steps=19,\n",
    "    ckpt=\"best_ema_inference_epoch_model.pt\",\n",
    "    confidence_ckpt=\"best_model_epoch75.pt\",\n",
    "    confidence_model_dir=\"./workdir/v1.1/confidence_model\",\n",
    "    different_schedules=False,\n",
    "    inf_sched_alpha=1,\n",
    "    inf_sched_beta=1,\n",
    "    inference_steps=20,\n",
    "    initial_noise_std_proportion=1.4601642460337794,\n",
    "    limit_failures=5,\n",
    "    model_dir=\"./workdir/v1.1/score_model\",\n",
    "    no_final_step_noise=True,\n",
    "    no_model=False,\n",
    "    no_random=False,\n",
    "    no_random_pocket=False,\n",
    "    ode=False,\n",
    "    old_filtering_model=True,\n",
    "    old_score_model=False,\n",
    "    resample_rdkit=False,\n",
    "    samples_per_complex=10,\n",
    "    sigma_schedule=\"expbeta\",\n",
    "    temp_psi_rot=0.9022615585677628,\n",
    "    temp_psi_tor=0.5946212391366862,\n",
    "    temp_psi_tr=0.727287304570729,\n",
    "    temp_sampling_rot=2.06391612594481,\n",
    "    temp_sampling_tor=7.044261621607846,\n",
    "    temp_sampling_tr=1.170050527854316,\n",
    "    temp_sigma_data_rot=0.7464326999906034,\n",
    "    temp_sigma_data_tor=0.6943254174849822,\n",
    "    temp_sigma_data_tr=0.9299802531572672,\n",
    "    loglevel=\"WARNING\",\n",
    "    choose_residue=False,\n",
    "    out_dir=\"results/user_inference\",\n",
    "    save_visualisation=False,\n",
    "    batch_size=10\n",
    ")\n",
    "\n",
    "def test_inference(api_url, progress_url, inference_input, inference_config):\n",
    "    response = requests.post(api_url, json={\"input\": inference_input.dict(), \"config\": inference_config.dict()})\n",
    "    if response.status_code == 200:\n",
    "        print(\"Inference initiated successfully\")\n",
    "        response_data = response.json()\n",
    "        task_id = response_data[\"task_id\"]\n",
    "        print(\"Task ID:\", task_id)\n",
    "        \n",
    "        # Check progress periodically\n",
    "        while True:\n",
    "            progress_response = requests.get(f\"{progress_url}{task_id}\")\n",
    "            if progress_response.status_code == 200:\n",
    "                progress_data = progress_response.json()\n",
    "                print(\"Progress:\", progress_data[\"progress\"])\n",
    "                if \"Completed\" in progress_data[\"progress\"]:\n",
    "                    break\n",
    "            else:\n",
    "                print(\"Failed to get progress\")\n",
    "            time.sleep(5)\n",
    "            \n",
    "    else:\n",
    "        print(\"Failed to start inference\")\n",
    "        print(\"Status Code:\", response.status_code)\n",
    "        print(\"Response:\", response.text)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_inference(api_url, progress_url, inference_input, inference_config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test script for zip input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/diffdock/lib/python3.9/site-packages/pydantic/_internal/_fields.py:149: UserWarning: Field \"model_dir\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference initiated successfully\n",
      "Task ID: 102bda99-afe3-4c2e-9465-083a5105db82\n",
      "Progress: No such task\n",
      "Progress: No such task\n",
      "Progress: No such task\n",
      "Progress: No such task\n",
      "Progress: No such task\n",
      "Progress: No such task\n",
      "Progress: No such task\n",
      "Progress: No such task\n",
      "Progress: No such task\n",
      "Progress: No such task\n",
      "Progress: No such task\n",
      "Progress: No such task\n",
      "Progress: No such task\n",
      "Progress: No such task\n",
      "Progress: No such task\n",
      "Progress: No such task\n",
      "Progress: No such task\n",
      "Progress: No such task\n",
      "Progress: No such task\n",
      "Progress: No such task\n",
      "Results downloaded successfully and saved to 102bda99-afe3-4c2e-9465-083a5105db82_output.zip\n"
     ]
    }
   ],
   "source": [
    "# test_script_zip.py\n",
    "import requests\n",
    "import time\n",
    "from pathlib import Path\n",
    "from schemas import InferenceConfig\n",
    "import json\n",
    "\n",
    "# Define the URL of the FastAPI server\n",
    "api_url = \"http://127.0.0.1:8000/inference/zip/\"\n",
    "progress_url = \"http://127.0.0.1:8000/inference/progress/\"\n",
    "download_url = \"http://127.0.0.1:8000/inference/download/\"\n",
    "\n",
    "# Path to the test zip archive\n",
    "zip_file_path = \"/root/projects/DiffDock/data/1a0q_test_data.zip\"\n",
    "\n",
    "# Example inference configuration\n",
    "inference_config = InferenceConfig(\n",
    "    actual_steps=19,\n",
    "    ckpt=\"best_ema_inference_epoch_model.pt\",\n",
    "    confidence_ckpt=\"best_model_epoch75.pt\",\n",
    "    confidence_model_dir=\"./workdir/v1.1/confidence_model\",\n",
    "    different_schedules=False,\n",
    "    inf_sched_alpha=1,\n",
    "    inf_sched_beta=1,\n",
    "    inference_steps=20,\n",
    "    initial_noise_std_proportion=1.4601642460337794,\n",
    "    limit_failures=5,\n",
    "    model_dir=\"./workdir/v1.1/score_model\",\n",
    "    no_final_step_noise=True,\n",
    "    no_model=False,\n",
    "    no_random=False,\n",
    "    no_random_pocket=False,\n",
    "    ode=False,\n",
    "    old_confidence_model=True,\n",
    "    old_score_model=False,\n",
    "    resample_rdkit=False,\n",
    "    samples_per_complex=10,\n",
    "    sigma_schedule=\"expbeta\",\n",
    "    temp_psi_rot=0.9022615585677628,\n",
    "    temp_psi_tor=0.5946212391366862,\n",
    "    temp_psi_tr=0.727287304570729,\n",
    "    temp_sampling_rot=2.06391612594481,\n",
    "    temp_sampling_tor=7.044261621607846,\n",
    "    temp_sampling_tr=1.170050527854316,\n",
    "    temp_sigma_data_rot=0.7464326999906034,\n",
    "    temp_sigma_data_tor=0.6943254174849822,\n",
    "    temp_sigma_data_tr=0.9299802531572672,\n",
    "    loglevel=\"WARNING\",\n",
    "    choose_residue=False,\n",
    "    out_dir=\"results/user_inference\",\n",
    "    save_visualisation=False,\n",
    "    batch_size=10\n",
    ")\n",
    "\n",
    "def test_inference_from_zip(api_url, progress_url, download_url, zip_file_path, config):\n",
    "    with open(zip_file_path, \"rb\") as f:\n",
    "        files = {\"zip_file\": f}\n",
    "        config_json = json.dumps(config.model_dump())\n",
    "        data = {\"config\": config_json}\n",
    "        response = requests.post(api_url, files=files, data=data)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        print(\"Inference initiated successfully\")\n",
    "        response_data = response.json()\n",
    "        task_id = response_data[\"task_id\"]\n",
    "        print(\"Task ID:\", task_id)\n",
    "        \n",
    "        # Check progress periodically\n",
    "        for _ in range(20):  # Wait long enough to ensure process has time to start\n",
    "            progress_response = requests.get(f\"{progress_url}{task_id}\")\n",
    "            if progress_response.status_code == 200:\n",
    "                progress_data = progress_response.json()\n",
    "                print(\"Progress:\", progress_data[\"progress\"])\n",
    "                if progress_data[\"progress\"] == \"Completed\":\n",
    "                    break\n",
    "            else:\n",
    "                print(\"Failed to get progress\")\n",
    "            time.sleep(5)\n",
    "        \n",
    "        # Download the results\n",
    "        download_response = requests.get(f\"{download_url}{task_id}\")\n",
    "        if download_response.status_code == 200:\n",
    "            output_zip_path = Path(f\"{task_id}_output.zip\")\n",
    "            with open(output_zip_path, \"wb\") as f:\n",
    "                f.write(download_response.content)\n",
    "            print(f\"Results downloaded successfully and saved to {output_zip_path}\")\n",
    "        else:\n",
    "            print(\"Failed to download results\")\n",
    "            print(\"Status Code:\", download_response.status_code)\n",
    "            print(\"Response:\", download_response.text)\n",
    "    else:\n",
    "        print(\"Failed to start inference\")\n",
    "        print(\"Status Code:\", response.status_code)\n",
    "        print(\"Response:\", response.text)\n",
    "\n",
    "# Run the test\n",
    "if __name__ == \"__main__\":\n",
    "    test_inference_from_zip(api_url, progress_url, download_url, zip_file_path, inference_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffdock",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
