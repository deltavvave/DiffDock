{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference initiated successfully\n",
      "Task ID: 5d2dbacb-b806-46b8-8643-ff218e07c3c6\n",
      "Progress: No such task\n",
      "Progress: No such task\n",
      "Progress: No such task\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 81\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResponse:\u001b[39m\u001b[38;5;124m\"\u001b[39m, response\u001b[38;5;241m.\u001b[39mtext)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 81\u001b[0m     \u001b[43mtest_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minference_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minference_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 73\u001b[0m, in \u001b[0;36mtest_inference\u001b[0;34m(api_url, progress_url, inference_input, inference_config)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to get progress\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 73\u001b[0m         \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to start inference\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# test_script.py\n",
    "\n",
    "import requests\n",
    "from schemas import InferenceInput, InferenceConfig\n",
    "import time\n",
    "\n",
    "# Define the URL of the FastAPI server\n",
    "api_url = \"http://127.0.0.1:8000/inference/\"\n",
    "progress_url = \"http://127.0.0.1:8000/inference/progress/\"\n",
    "\n",
    "# Example input data\n",
    "inference_input = InferenceInput(\n",
    "    protein_path=\"examples/6ahs_protein_processed.pdb\",\n",
    "    ligand_description=\"examples/6ahs_ligand.sdf\"\n",
    ")\n",
    "\n",
    "inference_config = InferenceConfig(\n",
    "    actual_steps=19,\n",
    "    ckpt=\"best_ema_inference_epoch_model.pt\",\n",
    "    confidence_ckpt=\"best_model_epoch75.pt\",\n",
    "    confidence_model_dir=\"./workdir/v1.1/confidence_model\",\n",
    "    different_schedules=False,\n",
    "    inf_sched_alpha=1,\n",
    "    inf_sched_beta=1,\n",
    "    inference_steps=20,\n",
    "    initial_noise_std_proportion=1.4601642460337794,\n",
    "    limit_failures=5,\n",
    "    model_dir=\"./workdir/v1.1/score_model\",\n",
    "    no_final_step_noise=True,\n",
    "    no_model=False,\n",
    "    no_random=False,\n",
    "    no_random_pocket=False,\n",
    "    ode=False,\n",
    "    old_filtering_model=True,\n",
    "    old_score_model=False,\n",
    "    resample_rdkit=False,\n",
    "    samples_per_complex=10,\n",
    "    sigma_schedule=\"expbeta\",\n",
    "    temp_psi_rot=0.9022615585677628,\n",
    "    temp_psi_tor=0.5946212391366862,\n",
    "    temp_psi_tr=0.727287304570729,\n",
    "    temp_sampling_rot=2.06391612594481,\n",
    "    temp_sampling_tor=7.044261621607846,\n",
    "    temp_sampling_tr=1.170050527854316,\n",
    "    temp_sigma_data_rot=0.7464326999906034,\n",
    "    temp_sigma_data_tor=0.6943254174849822,\n",
    "    temp_sigma_data_tr=0.9299802531572672,\n",
    "    loglevel=\"WARNING\",\n",
    "    choose_residue=False,\n",
    "    out_dir=\"results/user_inference\",\n",
    "    save_visualisation=False,\n",
    "    batch_size=10\n",
    ")\n",
    "\n",
    "def test_inference(api_url, progress_url, inference_input, inference_config):\n",
    "    response = requests.post(api_url, json={\"input\": inference_input.dict(), \"config\": inference_config.dict()})\n",
    "    if response.status_code == 200:\n",
    "        print(\"Inference initiated successfully\")\n",
    "        response_data = response.json()\n",
    "        task_id = response_data[\"task_id\"]\n",
    "        print(\"Task ID:\", task_id)\n",
    "        \n",
    "        # Check progress periodically\n",
    "        while True:\n",
    "            progress_response = requests.get(f\"{progress_url}{task_id}\")\n",
    "            if progress_response.status_code == 200:\n",
    "                progress_data = progress_response.json()\n",
    "                print(\"Progress:\", progress_data[\"progress\"])\n",
    "                if \"Post-processing Results\" in progress_data[\"progress\"]:\n",
    "                    break\n",
    "            else:\n",
    "                print(\"Failed to get progress\")\n",
    "            time.sleep(5)\n",
    "            \n",
    "    else:\n",
    "        print(\"Failed to start inference\")\n",
    "        print(\"Status Code:\", response.status_code)\n",
    "        print(\"Response:\", response.text)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_inference(api_url, progress_url, inference_input, inference_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffdock",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
