FROM nvidia/cuda:11.8.0-runtime-ubuntu22.04

# Set environment variables
ENV APPUSER="appuser"
ENV HOME=/home/$APPUSER
ENV ENV_NAME="mydiffdock"
ENV DIR_NAME="DiffDock"
ENV MAMBA_ROOT_PREFIX=$HOME/micromamba
ENV PATH=$HOME/bin:$HOME/.local/bin:$PATH

# Install necessary packages and micromamba
RUN apt-get update -y && apt-get install -y \
    wget curl git build-essential gcc-9 \
    && rm -rf /var/lib/apt/lists/* \
    && curl -Ls https://micro.mamba.pm/api/micromamba/linux-64/latest | tar -xj bin/micromamba

# Create Conda environment and install dependencies
COPY ./mydiffdock2.yml /tmp/mydiffdock2.yml
RUN micromamba create -n $ENV_NAME -f /tmp/mydiffdock2.yml \
    && micromamba run -n $ENV_NAME pip install setuptools packaging \
    && micromamba run -n $ENV_NAME pip install torch-scatter==2.1.0+pt113cu117 torch-sparse==0.6.15 torch-cluster==1.6.0 torch-spline-conv==1.2.1 torch-geometric==2.0.4 -f https://data.pyg.org/whl/torch-1.13.0+cu117.html \
    && micromamba clean -afy --quiet

# Copy application code
COPY . $HOME/$DIR_NAME
WORKDIR $HOME/$DIR_NAME

# Initialize micromamba and precompute series
RUN micromamba shell init -s bash --root-prefix $MAMBA_ROOT_PREFIX \
    && micromamba run -n $ENV_NAME python utils/precompute_series.py

# Expose port for FastAPI
EXPOSE 8000

# Create user results directory
RUN mkdir -p /home/appuser/DiffDock/results/user_inference && \
    chmod 777 /home/appuser/DiffDock/results/user_inference

# Default command to run the FastAPI application
CMD ["sh", "-c", "micromamba run -n ${ENV_NAME} uvicorn diffdock_api:app --host 0.0.0.0 --port 8000 --reload"]